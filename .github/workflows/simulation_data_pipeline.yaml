name: Simulation Data Pipeline

on:
  workflow_dispatch:
    inputs:
      simulation_size:
        description: 'Number of simulation iterations'
        required: true
        default: '100000'
        type: string

permissions:
  contents: write

jobs:
  run-simulation:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Run simulation
        run: |
          make log
          for attempt in {1..10}; do
            echo "Simulation attempt $attempt"
            if ./a.out ${{ inputs.simulation_size }}; then
              echo "Simulation successful"
              break
            fi
            if [ $attempt -eq 10 ]; then
              echo "Maximum attempts reached. Simulation failed."
              exit 1
            fi
          done

      - name: Install GitHub CLI
        run: |
          type -p curl >/dev/null || (sudo apt update && sudo apt install curl -y)
          curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg \
          && sudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg \
          && echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null \
          && sudo apt update \
          && sudo apt install gh -y

      - name: Process and upload data
        if: success()
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Get date and timestamp
          DATETIME=$(date +"%Y-%m-%d_%H-%M-%S")
          CSV_FILE=$(ls *_control_data.csv)
          
          # Create release with unique timestamp
          gh release create "simulation-${DATETIME}" \
            --title "Simulation Run ${DATETIME}" \
            --notes "Simulation data for ${DATETIME}"
          
          # Compress and split file
          echo "Compressing data file..."
          xz -9 "$CSV_FILE"
          
          # Split into 500MB chunks
          echo "Splitting compressed file..."
          split -b 500M "${CSV_FILE}.xz" "${CSV_FILE}.xz.part_"
          
          # Upload each part
          echo "Uploading file parts..."
          for part in ${CSV_FILE}.xz.part_*; do
            echo "Uploading $part..."
            gh release upload "simulation-${DATETIME}" "$part" --clobber
            
            # Add small delay between uploads
            sleep 2
          done
          
          # Cleanup
          echo "Cleaning up temporary files..."
          rm ${CSV_FILE}.xz.part_*
          
          echo "Upload complete!"